<<<<<<< Updated upstream
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords('german')) %>%
tm_map(stemDocument)
library(wordcloud2)
library(tm)
library(wordcloud)
library(SnowballC)
jeopCorpus <- Corpus(VectorSource(rstats$clean_tweet)) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords('german')) %>%
tm_map(stemDocument)
library(pacman)
p_load(tidyverse,igraph,ggraph,rtweet,hrbrthemes)
rstats <-readRDS("rstatssrf1301.RDS")
library(wordcloud2)
library(tm)
library(wordcloud)
library(SnowballC)
library("textcat")
library("stringr")
library(tidyverse)
rstats$clean_tweet = gsub("&amp", "", rstats$text)
rstats$clean_tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("@\\w+", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("[[:punct:]]", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("[[:digit:]]", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("http\\w+", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("[ \t]{2,}", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("^\\s+|\\s+$", "", rstats$clean_tweet)
#welche sprache?
rstats$lang <- unlist(textcat(rstats$clean_tweet))
rstats <- rstats %>% filter(lang=="german")
jeopCorpus <- Corpus(VectorSource(rstats$clean_tweet)) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords('german')) %>%
tm_map(stemDocument)
rstats$clean_tweet<- iconv(rstats$clean_tweet, "ASCII", "UTF-8", sub="")
View(rstats)
jeopCorpus[["content"]]
rstats <-readRDS("rstatssrf1301.RDS")
rstats$clean_tweet = gsub("@\\w+", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("[[:punct:]]", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("[[:digit:]]", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", rstats$clean_tweet)
#welche sprache?
rstats$lang <- unlist(textcat(rstats$clean_tweet))
rstats <- rstats %>% filter(lang=="german")
jeopCorpus <- Corpus(VectorSource(rstats$clean_tweet))
dtm <- TermDocumentMatrix(jeopCorpus)
jeopCorpus <- Corpus(VectorSource(rstats$clean_tweet)) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords('german')) %>%
tm_map(stemDocument)
jeopCorpus$`4`
jeopCorpus <- Corpus(VectorSource(rstats$clean_tweet)) %>%
tm_map(content_transformer(tolower))
rstats$clean_tweet = gsub("&amp", "", rstats$text)
rstats$clean_tweet = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("@\\w+", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("[[:punct:]]", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("[[:digit:]]", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("http\\w+", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("[ \t]{2,}", "", rstats$clean_tweet)
rstats$clean_tweet = gsub("^\\s+|\\s+$", "", rstats$clean_tweet)
View(rstats)
jeopCorpus <- Corpus(VectorSource(rstats$clean_tweet))
jeopCorpus <- Corpus(VectorSource(rstats$clean_tweet)) %>%
tm_map(content_transformer(tolower))
jeopCorpus[[1]]$content
jeopCorpus <- Corpus(VectorSource(rstats$clean_tweet)) %>%
tm_map(content_transformer(tolower))
jeopCorpus <- Corpus(VectorSource(rstats$clean_tweet)) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords('german')) %>%
tm_map(stemDocument)
jeopCorpus[[1]]$content
dtm <- TermDocumentMatrix(jeopCorpus)
rstats$clean_tweet =str_replace_all(rstats$clean_tweet,"[^[:graph:]]", " ")
jeopCorpus <- Corpus(VectorSource(rstats$clean_tweet)) %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords('german')) %>%
tm_map(stemDocument)
jeopCorpus[[1]]$content
dtm <- TermDocumentMatrix(jeopCorpus)
tm_map(jeopCorpus, function(x) iconv(enc2utf8(x), sub = "byte"))
dtm <- TermDocumentMatrix(jeopCorpus)
jeopCorpus <- Corpus(VectorSource(rstats$clean_tweet)) %>%
tm_map(removePunctuation) %>%
tm_map(tolower) %>%
tm_map(removeWords, stopwords('german')) %>%
tm_map(stemDocument)
jeopCorpus[[1]]$content
tm_map(jeopCorpus, function(x) iconv(enc2utf8(x), sub = "byte"))
dtm <- TermDocumentMatrix(jeopCorpus)
rstats$clean_tweet =str_replace_all(rstats$clean_tweet,"[^[:graph:]]", " ")
jeopCorpus <- Corpus(VectorSource(rstats$clean_tweet)) %>%
tm_map(removePunctuation) %>%
tm_map(tolower) %>%
tm_map(removeWords, stopwords('german')) %>%
tm_map(stemDocument)
jeopCorpus[[1]]$content
dtm <- TermDocumentMatrix(jeopCorpus)
tm_map(jeopCorpus, function(x) iconv(enc2utf8(x), sub = "byte"))
dtm <- TermDocumentMatrix(jeopCorpus)
jeopCorpus<-tm_map(jeopCorpus, function(x) iconv(enc2utf8(x), sub = "byte"))
dtm <- TermDocumentMatrix(jeopCorpus)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
wordcloud2(demoFreq, figPath = "C:/Users/Thomas/Documents/R/twitter/schweiz.jpg")
wordcloud2(demoFreq, figPath = "schweiz.jpg")
wordcloud2(demoFreq, figPath = "schweiz.jpeg")
wordcloud2(demoFreq, figPath = "schweiz.png")
wordcloud2(demoFreq, figPath = "schweiz.png")
wordcloud2(d, figPath = "schweiz.png")
wordcloud2(dtm, figPath = "schweiz.png")
wordcloud2(d, figPath = "schweiz.png")
wordcloud2(d, figPath = "schweiz.png")
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
wordcloud2(d, figPath = "schweiz.png")
wordcloud2(d, figPath = "swiss.png")
wordcloud2(d, figPath = "swiss.jpg")
wordcloud2(d, figPath = "swiss.jpg")
wordcloud2(d, figPath = "swiss.jpg")
demoFreq
d
wordcloud2(d, figPath = "swiss.jpg")
wordcloud2(d, figPath = "swiss.jpg")
wordcloud2(demoFreq, figPath = "swiss.jpg")
letterCloud(d,"#NOBILLAG")
library(wordcloud2)
library(tm)
library(wordcloud)
library(SnowballC)
library("textcat")
library("stringr")
library(tidyverse)
letterCloud(d,"#NOBILLAG")
letterCloud(d,"NOBILLAG")
View(d)
?mean
library(pacman)
p_load(tidyverse,igraph,ggraph,rtweet,hrbrthemes)
library(showtext)
## Loading Google fonts (http://www.google.com/fonts)
font_add_google("Raleway", "raleway")
showtext_auto()
rstats <-readRDS("rstatssrf1301.RDS")youtu
rstats <-readRDS("rstatssrf1301.RDS")
# glimpse(rstats)
#
# filter(rstats, retweet_count > 0) %>%
#   select(text, mentions_screen_name, retweet_count) %>%
#   mutate(text = substr(text, 1, 30)) %>%
#   unnest()
#
#
# filter(rstats, str_detect(text, "(RT|via)((?:[[:blank:]:]\\W*@\\w+)+)")) %>%
#   select(text, mentions_screen_name, retweet_count) %>%
#   mutate(extracted = str_match(text, "(RT|via)((?:[[:blank:]:]\\W*@\\w+)+)")[,3]) %>%
#   mutate(text = substr(text, 1, 30)) %>%
#   unnest()
filter(rstats, retweet_count > 5) %>%
select(screen_name, mentions_screen_name) %>%
unnest(mentions_screen_name) %>%
filter(!is.na(mentions_screen_name)) %>%
graph_from_data_frame() -> rt_g
ggplot(data_frame(y=degree_distribution(rt_g), x=1:length(y))) +
geom_segment(aes(x, y, xend=x, yend=0), color="slateblue") +
scale_y_continuous(expand=c(0,0), trans="sqrt") +
labs(x="Degree", y="Density (sqrt scale)", title="#rstats Retweet Degree Distribution")
# theme_ipsum_rc(grid="Y", axis="x")
V(rt_g)$node_label <- unname(ifelse(degree(rt_g)[V(rt_g)] > 25, names(V(rt_g)), ""))
V(rt_g)$node_size <- unname(ifelse(degree(rt_g)[V(rt_g)] > 25, degree(rt_g), 0))
# gg1 <-
ggraph(rt_g, layout = 'linear', circular = TRUE) +
geom_edge_arc(edge_width=0.0755, aes(alpha=..index..)) +
geom_node_label(aes(label=node_label, size=node_size),
label.size=0, fill="#ffffff66", segment.colour="springgreen",
color="slateblue", repel=TRUE, fontface="bold") +
coord_fixed() +
scale_size_area(trans="sqrt") +
labs(title="Retweet Relationships", subtitle="Namen mit den meisten Retweets gelabelt.\nDarkers edges == more retweets. Node size == larger degree") +
theme_graph(base_family="raleway") +
theme(legend.position="none")
# gg1
ggsave("graph.png", units="cm",width = 20, height = 20)
#
install.packages("keras")
# Load in the keras package
library(keras)
# Install TensorFlow
install_tensorflow()
# Load in the keras package
library(keras)
# Install TensorFlow
install_tensorflow()
# Klassifizierung der User nach Pro / Kontra funktioniert fÃ¼r die Top-Twitterer relativ gut
userkontra <-tweetpredictall %>% group_by(user,predcat) %>% summarize(anteil=n()/sum(n())) %>% arrange(desc(anteil))
library(rtweet)
library(rtweet)
nobillag <- search_tweets("#nobillag", n=5000)
neinzunobillag <- search_tweets("#neinzunobillag", n=5000)
nonobillag <- search_tweets("#nonobillag", n=5000)
nobillag_date <-bind_rowds(nobillag,neinzunobillag,nonobillag) %>% distinct(status_id,keep_all=T)
saveRDS(nobillag_date,"nobillag_11022018.RDS")
blogdown::new_site(theme="digitalcraftsman/hugo-minimalist-theme")
blogdown::new_site(theme="digitalcraftsman/hugo-minimalist-theme")
shiny::runApp('abstweets/example')
runApp('abstweets')
devtools::install_github("JohnCoene/echarts")
devtools::install_github("JohnCoene/echarts4r")
shiny::runApp('abstweets')
runApp('abstweets')
runApp('abstweets')
library(pacman)
pacman::p_load(rgdal, rgeos,ggplot2)
devtools::install_github("tidyverse/ggplot2")
devtools::install_github("tidyverse/ggplot2")
require(ggplot2)
install.packages("rlang")
install.packages("rlang")
library(pacman)
pacman::p_load(rgdal, rgeos,ggplot2)
#ggplot2 version?
# devtools::install_github("tidyverse/ggplot2")
# require(ggplot2)
#read shapefile with rgdal (in past i've regularly used maptools::readShapePoly) this results in a nested datastructure (lists within lists) which is hard to decompose
shape <- readOGR("geodata/Shape_detailliert_SEEN_2016/UP_GEMEINDEN_SEEN_2016_F.shp")
#fortify -> generates a dataframe which ggplot2 can handle from a spatial object
shape2 <- fortify(shape, region='BFS')
# Dataset (Motorization and "generalabonnement"-owners)
mfz_ga <-readRDS("mfz_ga.rds")
#merge data with shapefile
mapdata <- merge(shape2, mfz_ga, by.x="id", by.y="bfs",all.x = TRUE, all.y = TRUE)
mapdata <- mapdata[order(mapdata$order),]
#how does the df look like?
mapdata[11300:11310,]
# ggplot mapping  # data layer
ggplot(data=mapdata,aes(x=long, y=lat, group=group)) +
geom_path(color='gray') +
coord_equal()+
geom_polygon(aes(fill=Anteil_GA),color = "white")+
theme_void()+
theme(legend.key.size = unit(1,"line"),
#GrÃ¶sse Legende
legend.key.height= unit(0.5,"line"))+
scale_fill_continuous(name="GA pro 100 EW")+
labs(title="GA-Dichte im Kanton ZÃ¼rich",
subtitle="Anzahl Generalabonnemente pro 100 Einwohner",x="",y="")
library(pacman)
pacman::p_load(sp,sf,dplyr,ggplot2)
#Shapefile (municipalities) - read_sf generates a tidy dataset, each row represents one municipality, the polygons are stored in a single special geo-variable, the 'geometry' column
gemeinden<- read_sf('geodata/Shape_detailliert_SEEN_2016', stringsAsFactors = FALSE)
# Dataset (Motorization and GA-owners)
mfz_ga <-readRDS("mfz_ga.rds")
#join data - the dataset-structure stays the same, just
gemdata <-gemeinden %>% left_join(mfz_ga, by=c("BFS"="bfs"))
#how does the df with class "sf" look like?
head(gemdata)
# dataframe with class sf can easily be ploted to get an overview! not so with sp...
plot(gemdata)
#map with ggplot2
sfmap <-ggplot()+
geom_sf(data=gemdata,aes(fill=Anteil_GA),color = "white")+
coord_sf(datum = NA)+
theme_void()+#Koordinatennetz verbergen
theme(legend.key.size = unit(1,"line"),
legend.key.height= unit(0.5,"line"))+
scale_fill_continuous(name="GA pro 100 EW")+
labs(title="GA-Dichte im Kanton ZÃ¼rich",
subtitle="Anzahl Generalabonnemente pro 100 Einwohner",x="",y="")
sfmap
library(gghighlight)
#library(devtools)
#install_github(statistikZH/statR)
library(statR)
#library(devtools)
install_github(statistikZH/statR)
#library(devtools)
devtools::install_github(statistikZH/statR)
#library(devtools)
devtools::install_github("statistikZH/statR")
library(pacman)
pacman::p_load(rgdal, rgeos,ggplot2)
#ggplot2 version?
# devtools::install_github("tidyverse/ggplot2")
# require(ggplot2)
#read shapefile with rgdal (in past i've regularly used maptools::readShapePoly) this results in a nested datastructure (lists within lists) which is hard to decompose
shape <- readOGR("geodata/Shape_detailliert_SEEN_2016/UP_GEMEINDEN_SEEN_2016_F.shp")
#fortify -> generates a dataframe which ggplot2 can handle from a spatial object
shape2 <- fortify(shape, region='BFS')
# Dataset (Motorization and "generalabonnement"-owners)
mfz_ga <-readRDS("mfz_ga.rds")
#merge data with shapefile
mapdata <- merge(shape2, mfz_ga, by.x="id", by.y="bfs",all.x = TRUE, all.y = TRUE)
mapdata <- mapdata[order(mapdata$order),]
#how does the df look like?
mapdata[11300:11310,]
# ggplot mapping  # data layer
ggplot(data=mapdata,aes(x=long, y=lat, group=group)) +
geom_path(color='gray') +
coord_equal()+
geom_polygon(aes(fill=Anteil_GA),color = "white")+
theme_void()+
theme(legend.key.size = unit(1,"line"),
#GrÃ¶sse Legende
legend.key.height= unit(0.5,"line"))+
scale_fill_continuous(name="GA pro 100 EW")+
labs(title="GA-Dichte im Kanton ZÃ¼rich",
subtitle="Anzahl Generalabonnemente pro 100 Einwohner",x="",y="")
library(pacman)
pacman::p_load(sp,sf,dplyr,ggplot2)
#Shapefile (municipalities) - read_sf generates a tidy dataset, each row represents one municipality, the polygons are stored in a single special geo-variable, the 'geometry' column
gemeinden<- read_sf('geodata/Shape_detailliert_SEEN_2016', stringsAsFactors = FALSE)
# Dataset (Motorization and GA-owners)
mfz_ga <-readRDS("mfz_ga.rds")
#join data - the dataset-structure stays the same, just
gemdata <-gemeinden %>% left_join(mfz_ga, by=c("BFS"="bfs"))
#how does the df with class "sf" look like?
head(gemdata)
# dataframe with class sf can easily be ploted to get an overview! not so with sp...
plot(gemdata)
#map with ggplot2
sfmap <-ggplot()+
geom_sf(data=gemdata,aes(fill=Anteil_GA),color = "white")+
coord_sf(datum = NA)+
theme_void()+#Koordinatennetz verbergen
theme(legend.key.size = unit(1,"line"),
legend.key.height= unit(0.5,"line"))+
scale_fill_continuous(name="GA pro 100 EW")+
labs(title="GA-Dichte im Kanton ZÃ¼rich",
subtitle="Anzahl Generalabonnemente pro 100 Einwohner",x="",y="")
sfmap
library(gghighlight)
#library(devtools)
# devtools::install_github("statistikZH/statR")
# library(statR)
gghighlight_point(gemdata, aes(mfzpro100ew,Anteil_GA),Anteil_GA > 7 & mfzpro100ew<600 |
mfzpro100ew>1000|
mfzpro100ew<700 & Anteil_GA<3|
mfzpro100ew>750 & Anteil_GA>9)+
geom_point(aes(size=Anzahl_Einw/1000, color=Anteil_HTA))+
# theme_stat()+
scale_size(name="Einwohner")+
labs(title="Motorisierungsgrad & Generalabonnements pro Gemeinde\n",
y="Anzahl GA pro 100 Einwohner",x="Motorfahrzeuge pro 1000 Einwohner")
# Shapefiles of the "HandlungsrÃ¤ume & Bauzonen"
handlungsraum<- st_read("geodata/handlungsraeume", stringsAsFactors = FALSE)
bauzonen <- st_read("geodata/bauzonen", stringsAsFactors = FALSE)
sfmap+
geom_sf(data=handlungsraum,fill=NA)+
geom_sf(data=bauzonen,alpha=0.5,color="white")+
coord_sf(datum = NA)
# #CRS CH LV95 -> swiss projection
# st_crs(gemeinden)<- "+init=epsg:2056"
#Projektion wgs 84 lat lng
# sbb <- st_transform(sbb,"+init=epsg:4326 +proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +units=m +no_defs")
library(pacman)
pacman::p_load(rgdal, rgeos,ggplot2)
#ggplot2 version?
# devtools::install_github("tidyverse/ggplot2")
# require(ggplot2)
#read shapefile with rgdal (in past i've regularly used maptools::readShapePoly) this results in a nested datastructure (lists within lists) which is hard to decompose
shape <- readOGR("geodata/Shape_detailliert_SEEN_2016/UP_GEMEINDEN_SEEN_2016_F.shp")
#fortify -> generates a dataframe which ggplot2 can handle from a spatial object
shape2 <- fortify(shape, region='BFS')
library(pacman)
pacman::p_load(rgdal, rgeos,ggplot2)
#ggplot2 version?
# devtools::install_github("tidyverse/ggplot2")
# require(ggplot2)
#read shapefile with rgdal (in past i've regularly used maptools::readShapePoly) this results in a nested datastructure (lists within lists) which is hard to decompose
shape <- readOGR("geodata/Shape_detailliert_SEEN_2016/UP_GEMEINDEN_SEEN_2016_F.shp")
#fortify -> generates a dataframe which ggplot2 can handle from a spatial object
shape2 <- fortify(shape, region='BFS')
library(pacman)
pacman::p_load(rgdal, rgeos,ggplot2)
#ggplot2 version?
# devtools::install_github("tidyverse/ggplot2")
require(ggplot2)
#read shapefile with rgdal (in past i've regularly used maptools::readShapePoly) this results in a nested datastructure (lists within lists) which is hard to decompose
shape <- readOGR("geodata/Shape_detailliert_SEEN_2016/UP_GEMEINDEN_SEEN_2016_F.shp")
#fortify -> generates a dataframe which ggplot2 can handle from a spatial object
shape2 <- fortify(shape, region='BFS')
?fortify
??fortify
library(pacman)
pacman::p_load(rgdal, rgeos,ggplot2)
#ggplot2 version?
# devtools::install_github("tidyverse/ggplot2")
require(ggplot2)
#read shapefile with rgdal (in past i've regularly used maptools::readShapePoly) this results in a nested datastructure (lists within lists) which is hard to decompose
shape <- readOGR("geodata/Shape_detailliert_SEEN_2016/UP_GEMEINDEN_SEEN_2016_F.shp")
#fortify -> generates a dataframe which ggplot2 can handle from a spatial object
shape2 <- ggplot2::fortify(shape, region='BFS')
library(pacman)
pacman::p_load(rgdal, rgeos,tidyverse)
#ggplot2 version?
# devtools::install_github("tidyverse/ggplot2")
#read shapefile with rgdal (in past i've regularly used maptools::readShapePoly) this results in a nested datastructure (lists within lists) which is hard to decompose
shape <- readOGR("geodata/Shape_detailliert_SEEN_2016/UP_GEMEINDEN_SEEN_2016_F.shp")
#fortify -> generates a dataframe which ggplot2 can handle from a spatial object
shape2 <- fortify(shape, region='BFS')
# Dataset (Motorization and "generalabonnement"-owners)
mfz_ga <-readRDS("mfz_ga.rds")
#merge data with shapefile
mapdata <- merge(shape2, mfz_ga, by.x="id", by.y="bfs",all.x = TRUE, all.y = TRUE)
mapdata <- mapdata[order(mapdata$order),]
#how does the df look like?
mapdata[11300:11310,]
# ggplot mapping  # data layer
ggplot(data=mapdata,aes(x=long, y=lat, group=group)) +
geom_path(color='gray') +
coord_equal()+
geom_polygon(aes(fill=Anteil_GA),color = "white")+
theme_void()+
theme(legend.key.size = unit(1,"line"),
#GrÃ¶sse Legende
legend.key.height= unit(0.5,"line"))+
scale_fill_continuous(name="GA pro 100 EW")+
labs(title="GA-Dichte im Kanton ZÃ¼rich",
subtitle="Anzahl Generalabonnemente pro 100 Einwohner",x="",y="")
library(pacman)
pacman::p_load(sp,sf,dplyr,ggplot2)
#Shapefile (municipalities) - read_sf generates a tidy dataset, each row represents one municipality, the polygons are stored in a single special geo-variable, the 'geometry' column
gemeinden<- read_sf('geodata/Shape_detailliert_SEEN_2016', stringsAsFactors = FALSE)
# Dataset (Motorization and GA-owners)
mfz_ga <-readRDS("mfz_ga.rds")
#join data - the dataset-structure stays the same, just
gemdata <-gemeinden %>% left_join(mfz_ga, by=c("BFS"="bfs"))
#how does the df with class "sf" look like?
head(gemdata)
# dataframe with class sf can easily be ploted to get an overview! not so with sp...
plot(gemdata)
#map with ggplot2
sfmap <-ggplot()+
geom_sf(data=gemdata,aes(fill=Anteil_GA),color = "white")+
coord_sf(datum = NA)+
theme_void()+#Koordinatennetz verbergen
theme(legend.key.size = unit(1,"line"),
legend.key.height= unit(0.5,"line"))+
scale_fill_continuous(name="GA pro 100 EW")+
labs(title="GA-Dichte im Kanton ZÃ¼rich",
subtitle="Anzahl Generalabonnemente pro 100 Einwohner",x="",y="")
detach(tidyverse)
library(pacman)
detach(tidyverse)
#map with ggplot2
sfmap <-ggplot()+
geom_sf(data=gemdata,aes(fill=Anteil_GA),color = "white")+
coord_sf(datum = NA)+
theme_void()+#Koordinatennetz verbergen
theme(legend.key.size = unit(1,"line"),
legend.key.height= unit(0.5,"line"))+
scale_fill_continuous(name="GA pro 100 EW")+
labs(title="GA-Dichte im Kanton ZÃ¼rich",
=======
>>>>>>> Stashed changes
subtitle="Anzahl Generalabonnemente pro 100 Einwohner",x="",y="")
require(ggplot2)
library(pacman)
pacman::p_load(sp,sf,dplyr,ggplot2)
require(ggplot2)
#Shapefile (municipalities) - read_sf generates a tidy dataset, each row represents one municipality, the polygons are stored in a single special geo-variable, the 'geometry' column
gemeinden<- read_sf('geodata/Shape_detailliert_SEEN_2016', stringsAsFactors = FALSE)
# Dataset (Motorization and GA-owners)
mfz_ga <-readRDS("mfz_ga.rds")
#join data - the dataset-structure stays the same, just
gemdata <-gemeinden %>% left_join(mfz_ga, by=c("BFS"="bfs"))
#how does the df with class "sf" look like?
head(gemdata)
# dataframe with class sf can easily be ploted to get an overview! not so with sp...
plot(gemdata)
#map with ggplot2
sfmap <-ggplot()+
geom_sf(data=gemdata,aes(fill=Anteil_GA),color = "white")+
coord_sf(datum = NA)+
theme_void()+#Koordinatennetz verbergen
theme(legend.key.size = unit(1,"line"),
legend.key.height= unit(0.5,"line"))+
scale_fill_continuous(name="GA pro 100 EW")+
labs(title="GA-Dichte im Kanton ZÃ¼rich",
subtitle="Anzahl Generalabonnemente pro 100 Einwohner",x="",y="")
#ggplot2 version?
devtools::install_github("tidyverse/ggplot2")
shiny::runApp('abstweets')
shiny::runApp('abstweets')
pacman::p_load(tidyverse,echarts4r,shinythemes,DT,shiny,shinydashboardPlus)
runApp('abstweets')
library(tidyverse)
library(echarts4r)
library(shiny)
library(DT)
library(shinythemes)
runApp('abstweets')
runApp('abstweets')
runApp('abstweets')
gsg_raw <- read.csv("rawdata_gsg.csv")
setwd("~/abstweets")
gsg_raw <- read.csv("rawdata_gsg.csv")
vg_raw <- read.csv("rawdata_vg.csv")
astg_raw <- read.csv("rawdata_sd.csv")
runApp()
runApp()
runApp()
runApp()
<<<<<<< Updated upstream
runApp()
=======
shiny::runApp()
install.packages("echarts4r")
devtools::install_github("JohnCoene/echarts4r")
library(echarts4r)
library("echarts4r")
shiny::runApp()
tweets_sd<- readRDS("tweets_sd.rds")
View(tweets_sd)
>>>>>>> Stashed changes
